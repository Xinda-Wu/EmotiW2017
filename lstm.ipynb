{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_measure(predictions, labels):\n",
    "    \"\"\" calculate sum squared error of predictions \"\"\"\n",
    "    mistakes = tf.not_equal(tf.argmax(labels, 1), tf.argmax(predictions, 1))\n",
    "    return tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "    \n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\" Convert class labels from scalars to one-hot vectors. \"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def get_xy(start, end, vid, labels, feat):\n",
    "    inp, output = [], []\n",
    "    for i in range(start,end+1):\n",
    "        tmp = []\n",
    "        # check if number of frame in the current video are greater than 16\n",
    "        if len(feat[vid[i]]) > 16:\n",
    "            current_frame = random.randrange(0,len(feat[vid[i]])-16)\n",
    "            c_start = 0\n",
    "            c_end = current_frame+16\n",
    "            \n",
    "            for frame in sorted(feat[vid[i]]):\n",
    "                if (c_start > current_frame) and (c_end > current_frame):\n",
    "                    current_frame += 1\n",
    "                    tmp.append(feat[vid[i]][frame].flatten())\n",
    "                c_start += 1\n",
    "        else:\n",
    "            for frame in sorted(feat[vid[i]]):\n",
    "                tmp.append(feat[vid[i]][frame].flatten())\n",
    "            last_frame_id = sorted(feat[vid[i]])[-1]\n",
    "            while len(tmp) <= 15:\n",
    "                tmp.append(feat[vid[i]][last_frame_id].flatten())\n",
    "        \n",
    "        inp.append(tmp)\n",
    "        output.append(labels[vid[i]])\n",
    "    output = dense_to_one_hot(np.array(output), n_classes)\n",
    "\n",
    "    return inp, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "n_input = 4096\n",
    "n_steps = 16\n",
    "n_hidden = 128\n",
    "n_classes = 7\n",
    "\n",
    "logs_path = 'logs/'\n",
    "subset = 'normal'\n",
    "root = 'backup/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_train = np.load(root+'feat_train.npy', encoding='latin1').item(0)\n",
    "feat_val = np.load(root+'feat_val.npy', encoding='latin1').item(0)\n",
    "\n",
    "vid_train = np.load(root+'vid_train.npy')\n",
    "vid_val = np.load(root+'vid_val.npy')\n",
    "\n",
    "labels_train = np.load(root+'labels_train.npy').item(0)\n",
    "labels_val = np.load(root+'labels_val.npy').item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "def lstm_model(subset)\n",
    "    with tf.name_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "        y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        cell = tf.contrib.rnn.LSTMCell(n_hidden)\n",
    "        val, _ = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "        val = tf.transpose(val, [1, 0, 2])\n",
    "        last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "\n",
    "    with tf.name_scope('weight'):\n",
    "    #     weight = tf.get_variable(name='weight',shape= [n_hidden, int(y.get_shape()[1])], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        weight = tf.get_variable(name='weight',shape= [n_hidden, int(y.get_shape()[1])], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    with tf.name_scope('bias'):\n",
    "    #     bias = tf.get_variable(name='bias',shape=[y.get_shape()[1]], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bias = tf.get_variable(name='bias',shape=[y.get_shape()[1]], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "\n",
    "    with tf.name_scope('softmax'):\n",
    "        pred = tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "    #     cross_entropy = -tf.reduce_sum(y * tf.log(tf.clip_by_value(pred,1e-10,1.0)))\n",
    "    #     cross_entropy = tf.reduce_mean(-tf.reduce_sum(pred * tf.log(y), reduction_indices=[1]))\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        minimize = optimizer.minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# create a summary for cross_entropy and accuracy\n",
    "tf.summary.scalar(\"cost\", cross_entropy)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# merge all summaries into a single \"operation\" which we can execute in a session \n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , acc_train: 30.8201045 acc_val: 19.6765497 , loss_trian: 1.8831360\n",
      "Epoch  1 , acc_train: 36.7724866 acc_val: 25.6064683 , loss_trian: 1.8426372\n",
      "Epoch  2 , acc_train: 39.5502657 acc_val: 26.9541770 , loss_trian: 1.8149766\n",
      "Epoch  3 , acc_train: 43.5185194 acc_val: 30.1886797 , loss_trian: 1.7835377\n",
      "Epoch  4 , acc_train: 39.9470896 acc_val: 28.5714298 , loss_trian: 1.7896413\n",
      "Epoch  5 , acc_train: 42.5925940 acc_val: 29.3800533 , loss_trian: 1.7622049\n",
      "Epoch  6 , acc_train: 46.5608478 acc_val: 33.6927235 , loss_trian: 1.7438910\n",
      "Epoch  7 , acc_train: 46.5608478 acc_val: 30.1886797 , loss_trian: 1.7449830\n",
      "Epoch  8 , acc_train: 50.9259284 acc_val: 33.9622647 , loss_trian: 1.7243435\n",
      "Epoch  9 , acc_train: 49.7354507 acc_val: 32.8840971 , loss_trian: 1.7159246\n",
      "Epoch  10 , acc_train: 50.9259284 acc_val: 29.9191386 , loss_trian: 1.6970786\n",
      "Epoch  11 , acc_train: 51.4550269 acc_val: 30.4582208 , loss_trian: 1.6965632\n",
      "Epoch  12 , acc_train: 53.0423284 acc_val: 34.2318058 , loss_trian: 1.6810403\n",
      "Epoch  13 , acc_train: 51.4550269 acc_val: 32.6145560 , loss_trian: 1.6895653\n",
      "Epoch  14 , acc_train: 52.6455045 acc_val: 32.0754707 , loss_trian: 1.6731567\n",
      "Epoch  15 , acc_train: 54.4973552 acc_val: 35.3099734 , loss_trian: 1.6628823\n",
      "Epoch  16 , acc_train: 56.0846567 acc_val: 33.4231794 , loss_trian: 1.6569281\n",
      "Epoch  17 , acc_train: 55.2910030 acc_val: 30.9973031 , loss_trian: 1.6646122\n",
      "Epoch  18 , acc_train: 56.2169313 acc_val: 32.0754707 , loss_trian: 1.6603379\n",
      "Epoch  19 , acc_train: 57.2751343 acc_val: 33.4231794 , loss_trian: 1.6475704\n",
      "Epoch  20 , acc_train: 56.0846567 acc_val: 32.6145560 , loss_trian: 1.6523105\n",
      "Epoch  21 , acc_train: 56.0846567 acc_val: 31.8059295 , loss_trian: 1.6499245\n",
      "Epoch  22 , acc_train: 58.2010567 acc_val: 33.9622647 , loss_trian: 1.6382000\n",
      "Epoch  23 , acc_train: 59.1269851 acc_val: 34.5013469 , loss_trian: 1.6280901\n",
      "Epoch  24 , acc_train: 58.2010567 acc_val: 33.6927235 , loss_trian: 1.6277527\n",
      "Epoch  25 , acc_train: 59.3915343 acc_val: 34.5013469 , loss_trian: 1.6278881\n",
      "Epoch  26 , acc_train: 59.9206328 acc_val: 35.3099734 , loss_trian: 1.6115650\n",
      "Epoch  27 , acc_train: 59.1269851 acc_val: 33.4231794 , loss_trian: 1.6211835\n",
      "Epoch  28 , acc_train: 60.4497373 acc_val: 32.3450148 , loss_trian: 1.6079021\n",
      "Epoch  29 , acc_train: 60.4497373 acc_val: 32.6145560 , loss_trian: 1.6064302\n",
      "Epoch  30 , acc_train: 62.0370388 acc_val: 36.3881409 , loss_trian: 1.5949752\n",
      "Epoch  31 , acc_train: 61.2433851 acc_val: 35.3099734 , loss_trian: 1.6022745\n",
      "Epoch  32 , acc_train: 61.7724895 acc_val: 33.1536382 , loss_trian: 1.5953979\n",
      "Epoch  33 , acc_train: 61.9047642 acc_val: 35.8490556 , loss_trian: 1.5837575\n",
      "Epoch  34 , acc_train: 61.6402090 acc_val: 33.9622647 , loss_trian: 1.5973716\n",
      "Epoch  35 , acc_train: 63.4920657 acc_val: 35.0404322 , loss_trian: 1.5842088\n",
      "Epoch  36 , acc_train: 63.3597910 acc_val: 30.9973031 , loss_trian: 1.5828847\n",
      "Epoch  37 , acc_train: 63.2275105 acc_val: 35.0404322 , loss_trian: 1.5821860\n",
      "Epoch  38 , acc_train: 62.8306866 acc_val: 35.5795145 , loss_trian: 1.5759174\n",
      "Epoch  39 , acc_train: 64.8148119 acc_val: 33.6927235 , loss_trian: 1.5732774\n",
      "Epoch  40 , acc_train: 63.4920657 acc_val: 33.1536382 , loss_trian: 1.5720124\n",
      "Epoch  41 , acc_train: 66.5343940 acc_val: 35.0404322 , loss_trian: 1.5598332\n",
      "Epoch  42 , acc_train: 65.3439164 acc_val: 32.8840971 , loss_trian: 1.5580822\n",
      "Epoch  43 , acc_train: 65.4761910 acc_val: 33.6927235 , loss_trian: 1.5573281\n",
      "Epoch  44 , acc_train: 65.6084657 acc_val: 33.1536382 , loss_trian: 1.5556790\n",
      "Epoch  45 , acc_train: 66.9312179 acc_val: 32.6145560 , loss_trian: 1.5524487\n",
      "Epoch  46 , acc_train: 66.7989433 acc_val: 31.8059295 , loss_trian: 1.5446461\n",
      "Epoch  47 , acc_train: 67.1957672 acc_val: 33.6927235 , loss_trian: 1.5454673\n",
      "Epoch  48 , acc_train: 66.7989433 acc_val: 31.5363884 , loss_trian: 1.5437661\n",
      "Epoch  49 , acc_train: 67.0634925 acc_val: 34.7708881 , loss_trian: 1.5416901\n",
      "Epoch  50 , acc_train: 67.3280418 acc_val: 33.4231794 , loss_trian: 1.5337096\n",
      "Epoch  51 , acc_train: 67.5925910 acc_val: 33.1536382 , loss_trian: 1.5346808\n",
      "Epoch  52 , acc_train: 67.7248657 acc_val: 31.8059295 , loss_trian: 1.5288405\n",
      "Epoch  53 , acc_train: 67.7248657 acc_val: 33.4231794 , loss_trian: 1.5314237\n",
      "Epoch  54 , acc_train: 67.7248657 acc_val: 31.2668473 , loss_trian: 1.5306687\n",
      "Epoch  55 , acc_train: 69.4444418 acc_val: 35.0404322 , loss_trian: 1.5301085\n",
      "Epoch  56 , acc_train: 67.7248657 acc_val: 35.5795145 , loss_trian: 1.5276312\n",
      "Epoch  57 , acc_train: 69.7089970 acc_val: 34.2318058 , loss_trian: 1.5156438\n",
      "Epoch  58 , acc_train: 70.3703701 acc_val: 37.4663085 , loss_trian: 1.5129417\n",
      "Epoch  59 , acc_train: 71.1640239 acc_val: 34.5013469 , loss_trian: 1.5073059\n",
      "Epoch  60 , acc_train: 70.8994687 acc_val: 33.4231794 , loss_trian: 1.5087261\n",
      "Epoch  61 , acc_train: 70.2380955 acc_val: 33.4231794 , loss_trian: 1.4993570\n",
      "Epoch  62 , acc_train: 70.6349194 acc_val: 35.0404322 , loss_trian: 1.5096536\n",
      "Epoch  63 , acc_train: 70.7671940 acc_val: 33.9622647 , loss_trian: 1.5002865\n",
      "Epoch  64 , acc_train: 69.4444418 acc_val: 34.7708881 , loss_trian: 1.5084952\n",
      "Epoch  65 , acc_train: 71.6931224 acc_val: 34.5013469 , loss_trian: 1.4958519\n",
      "Epoch  66 , acc_train: 71.4285731 acc_val: 34.2318058 , loss_trian: 1.4987406\n",
      "Epoch  67 , acc_train: 69.8412716 acc_val: 34.5013469 , loss_trian: 1.5016676\n",
      "Epoch  68 , acc_train: 70.7671940 acc_val: 32.8840971 , loss_trian: 1.4944181\n",
      "Epoch  69 , acc_train: 71.2962985 acc_val: 30.1886797 , loss_trian: 1.4908128\n",
      "Epoch  70 , acc_train: 71.5608478 acc_val: 33.9622647 , loss_trian: 1.4876240\n",
      "Epoch  71 , acc_train: 71.6931224 acc_val: 35.0404322 , loss_trian: 1.4766740\n",
      "Epoch  72 , acc_train: 70.7671940 acc_val: 32.6145560 , loss_trian: 1.4904753\n",
      "Epoch  73 , acc_train: 71.5608478 acc_val: 30.9973031 , loss_trian: 1.4858980\n",
      "Epoch  74 , acc_train: 71.8253970 acc_val: 35.0404322 , loss_trian: 1.4793447\n",
      "Epoch  75 , acc_train: 72.0899463 acc_val: 35.8490556 , loss_trian: 1.4768015\n",
      "Epoch  76 , acc_train: 73.8095224 acc_val: 33.6927235 , loss_trian: 1.4637280\n",
      "Epoch  77 , acc_train: 74.0740716 acc_val: 34.7708881 , loss_trian: 1.4591420\n",
      "Epoch  78 , acc_train: 72.7513254 acc_val: 34.7708881 , loss_trian: 1.4721389\n",
      "Epoch  79 , acc_train: 74.7354507 acc_val: 36.1185998 , loss_trian: 1.4612960\n",
      "Epoch  80 , acc_train: 74.6031761 acc_val: 31.2668473 , loss_trian: 1.4587152\n",
      "Epoch  81 , acc_train: 74.6031761 acc_val: 33.9622647 , loss_trian: 1.4539399\n",
      "Epoch  82 , acc_train: 74.7354507 acc_val: 35.3099734 , loss_trian: 1.4470464\n",
      "Epoch  83 , acc_train: 74.4709015 acc_val: 32.6145560 , loss_trian: 1.4507188\n",
      "Epoch  84 , acc_train: 75.3968239 acc_val: 31.8059295 , loss_trian: 1.4458607\n",
      "Epoch  85 , acc_train: 74.3386269 acc_val: 33.4231794 , loss_trian: 1.4486045\n",
      "Epoch  86 , acc_train: 74.4709015 acc_val: 35.3099734 , loss_trian: 1.4493144\n",
      "Epoch  87 , acc_train: 74.7354507 acc_val: 32.0754707 , loss_trian: 1.4446107\n",
      "Epoch  88 , acc_train: 75.3968239 acc_val: 34.5013469 , loss_trian: 1.4356638\n",
      "Epoch  89 , acc_train: 76.3227522 acc_val: 33.1536382 , loss_trian: 1.4348232\n",
      "Epoch  90 , acc_train: 74.4709015 acc_val: 32.8840971 , loss_trian: 1.4397465\n",
      "Epoch  91 , acc_train: 75.6613731 acc_val: 34.7708881 , loss_trian: 1.4333901\n",
      "Epoch  92 , acc_train: 75.7936537 acc_val: 33.1536382 , loss_trian: 1.4361888\n",
      "Epoch  93 , acc_train: 76.1904776 acc_val: 34.2318058 , loss_trian: 1.4307505\n",
      "Epoch  94 , acc_train: 78.0423284 acc_val: 33.6927235 , loss_trian: 1.4213903\n",
      "Epoch  95 , acc_train: 76.1904776 acc_val: 32.8840971 , loss_trian: 1.4304203\n",
      "Epoch  96 , acc_train: 78.0423284 acc_val: 33.9622647 , loss_trian: 1.4211432\n",
      "Epoch  97 , acc_train: 76.7195761 acc_val: 32.8840971 , loss_trian: 1.4190830\n",
      "Epoch  98 , acc_train: 76.4550269 acc_val: 33.9622647 , loss_trian: 1.4255402\n",
      "Epoch  99 , acc_train: 77.5132298 acc_val: 31.8059295 , loss_trian: 1.4199445\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    no_of_batches = int((len(feat_train)) / batch_size)\n",
    "    train_writer = tf.summary.FileWriter('%strain_%s/'%(logs_path, subset), sess.graph)\n",
    "    val_writer = tf.summary.FileWriter('%sval_%s/'%(logs_path, subset), sess.graph)\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        ptr = 0\n",
    "        np.random.shuffle(vid_train)\n",
    "        for j in range(no_of_batches):\n",
    "            inp, out = get_xy(ptr,ptr+batch_size, vid_train, labels_train, feat_train)\n",
    "            sess.run([minimize],{x: inp, y: out})\n",
    "            \n",
    "        r = random.randrange(0, len(feat_train)-300)\n",
    "        train_input, train_output = get_xy(0,len(feat_train)-1, vid_train, labels_train, feat_train)\n",
    "        val_input, val_output = get_xy(0,len(feat_val)-1, vid_val, labels_val, feat_val)\n",
    "                \n",
    "        loss_trian,  acc_train, summary_train, props_train = sess.run([cross_entropy, accuracy, summary_op, pred],{x: train_input, y: train_output})\n",
    "        train_writer.add_summary(summary_train,i)\n",
    "        \n",
    "        _, acc_val, summary_val, props_val = sess.run([cross_entropy, accuracy, summary_op, pred],{x: val_input, y: val_output})\n",
    "        val_writer.add_summary(summary_val,i)\n",
    "        # Save the variables to disk.\n",
    "#         if i %  25 == 0:\n",
    "#             save_path = saver.save(sess, \"backup/model_%d.ckpt\"%i)\n",
    "#             print(\"Model saved in file: %s\" % save_path)       \n",
    "        print(\"Epoch \",str(i), ', acc_train: %.7f' % (acc_train*100), 'acc_val: %.7f' % (acc_val*100), ', loss_trian: %.7f' % loss_trian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
